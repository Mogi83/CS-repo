{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a2a921",
   "metadata": {},
   "source": [
    "## CS233 - Homework 2 (100 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b75dd",
   "metadata": {},
   "source": [
    "### 1. String split (20 points)\n",
    "### Tasks\n",
    "1. split val (5 pts)\n",
    "2. remove surrounding white spaces (5 pts)\n",
    "3. convert all to lowercase and connect them with \" | \" (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7b812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  Alice ', '  Bob', 'Carol  ', ' dave  ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Alice', 'Bob', 'Carol', 'dave']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'alice | bob | carol | dave'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val = \"  Alice ,  Bob,Carol  , dave  \"\n",
    "# 1) split\n",
    "split = val.split(\",\")\n",
    "display(split)\n",
    "# expected output: ['  Alice ', '  Bob', 'Carol  ', ' dave  ']\n",
    "\n",
    "# 2) remove surrounding white spaces\n",
    "whitespace = [w.strip() for w in split]\n",
    "display(whitespace)\n",
    "# expected output: # ['Alice', 'Bob', 'Carol', 'dave']\n",
    "\n",
    "# 3) lowercase + join with \" | \"\n",
    "lower_joined = \" | \".join([c.lower() for c in whitespace])\n",
    "display(lower_joined)\n",
    "# expected output: 'alice | bob | carol | dave'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6269b4",
   "metadata": {},
   "source": [
    "### 2. Processing Large Datasets with `chunksize` (20 points)\n",
    "\n",
    "You are given a CSV file, named `large_sales.csv` containing sales transaction data with the following columns:\n",
    "\n",
    "- `transaction_id`  \n",
    "- `customer_id`  \n",
    "- `product_id`  \n",
    "- `quantity`  \n",
    "- `price`  \n",
    "\n",
    "Because the file is too large to fit in memory all at once, you need to process it in **chunks**.  \n",
    "\n",
    "---\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Write Python code that reads this file in chunks of 100,000. (5 pts)\n",
    "2. For each chunk, compute the total sales revenue, and keep a running total across all chunks. (10 pts)\n",
    "   ```python\n",
    "   revenue = quantity * price\n",
    "3. Print the overall total revenue. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad726ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revenue: $262,633,491.66\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunker = pd.read_csv(\"large_sales.csv\", chunksize=100_000)\n",
    "total_revenue = 0\n",
    "\n",
    "for chunk in chunker:\n",
    "    chunk_revenue = (chunk[\"quantity\"] * chunk[\"price\"]).sum()\n",
    "    total_revenue += chunk_revenue\n",
    "\n",
    "print(f\"Total revenue: ${total_revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438e1ff",
   "metadata": {},
   "source": [
    "### 3. Working with Other Delimited Formats (20 pts)\n",
    "\n",
    "You are given a text file named employees.txt that contains employee records separated by the | (pipe) character.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Load this file into a pandas DataFrame using pd.read_csv with the appropriate sep argument.\n",
    "\n",
    "2. Display the first 3 rows of the DataFrame. (5 pts)\n",
    "\n",
    "3. Compute the average salary of all employees. (5 pts)\n",
    "\n",
    "4. Find the highest-paid employee and print their name and salary. (5 pts)\n",
    "\n",
    "5.  Save only the employees in the Engineering department into a new tab-delimited file named engineering_employees.txt.\n",
    "\n",
    "6. Load your generated .txt file using the provided code below. (#5 and #6, 5 pts in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cc7f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows:\n",
      "   employee_id          name department  salary\n",
      "0          101     Grace Kim      Sales  104886\n",
      "1          102   Steve Davis    Finance   94131\n",
      "2          103  Helen Miller    Finance  117221\n",
      "\n",
      "Average salary: 84731.2\n",
      "\n",
      "Highest-paid employee: Frank Kim 119163 \n",
      "\n",
      "Engineering Employees:\n",
      "\n",
      "    Unnamed: 0  employee_id          name   department  salary\n",
      "0            5          106   Leo Johnson  Engineering   75658\n",
      "1           22          123  Mona Johnson  Engineering   90774\n",
      "2           23          124    Ian Miller  Engineering  117563\n",
      "3           30          131     Nina Wong  Engineering   56910\n",
      "4           33          134     Mona Wong  Engineering  104268\n",
      "5           40          141     Grace Lee  Engineering   80080\n",
      "6           41          142    Tina Brown  Engineering   59474\n",
      "7           45          146       Ian Kim  Engineering  101005\n",
      "8           48          149   Eva Johnson  Engineering   76736\n",
      "9           50          151    Eva Miller  Engineering  105680\n",
      "10          56          157   Paul Miller  Engineering   92107\n",
      "11          64          165  Quincy Smith  Engineering   70932\n",
      "12          84          185     Cathy Kim  Engineering  115726\n",
      "13          90          191     Bob Smith  Engineering   77751\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the file using | as the delimiter\n",
    "df = pd.read_csv(\"employees.txt\", sep=\"|\")\n",
    "\n",
    "# 2. Display first 3 rows\n",
    "print(\"First 3 rows:\")\n",
    "print(df.head(3))\n",
    "\n",
    "# 3. Compute average salary\n",
    "mean_salary = df[\"salary\"].mean()\n",
    "print(\"\\nAverage salary:\", mean_salary)\n",
    "\n",
    "# 4. Highest-paid employee\n",
    "top_paid = df.sort_values(\"salary\", ascending=False).iloc[0]\n",
    "print(\"\\nHighest-paid employee:\", top_paid[\"name\"],top_paid[\"salary\"],\"\\n\")\n",
    "\n",
    "# 5. Save Engineering employees to tab-delimited file\n",
    "eng_df = df[df[\"department\"] == \"Engineering\"]\n",
    "eng_df.to_csv(\"eng_employees.txt\", sep=\"\\t\")\n",
    "\n",
    "# 6 load your generated .txt from step 5\n",
    "check_df = pd.read_csv(\"eng_employees.txt\", sep=\"\\t\")\n",
    "print(\"Engineering Employees:\\n\")\n",
    "print(check_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e081c8",
   "metadata": {},
   "source": [
    "### 4. Working with HTML Data (20 pts)\n",
    "\n",
    "You are given an HTML file named **`products.html`** that contains a simple table of product information:\n",
    "\n",
    "##### Tasks\n",
    "\n",
    "1. load the HTML table into a DataFrame. \n",
    "\n",
    "2. display the DataFrame. (5 pts)\n",
    "\n",
    "3. Compute the average product price. (5 pts)\n",
    "\n",
    "4. Save only the products in the Electronics category into a new CSV file. (5 pts)\n",
    "\n",
    "5. Reload your new csv file and print it here. (5 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443bb00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id           name     category  price\n",
      "0         101         Laptop  Electronics   1200\n",
      "1         102     Desk Chair    Furniture    250\n",
      "2         103   Water Bottle       Sports     30\n",
      "3         104     Headphones  Electronics    150\n",
      "4         105  Standing Desk    Furniture    690\n",
      "5         106         Webcam  Electronics     90 \n",
      "\n",
      "Average product price:  401.6666666666667 \n",
      "\n",
      "   product_id        name     category  price\n",
      "0         101      Laptop  Electronics   1200\n",
      "1         104  Headphones  Electronics    150\n",
      "2         106      Webcam  Electronics     90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#1\n",
    "df = pd.read_html(\"products.html\")\n",
    "#print(len(df))\n",
    "product = df[0]\n",
    "\n",
    "#2\n",
    "print(product, \"\\n\")\n",
    "\n",
    "#3\n",
    "print(\"Average product price: \", product[\"price\"].mean(), \"\\n\")\n",
    "\n",
    "#4\n",
    "electronics = product[product[\"category\"] == \"Electronics\"]\n",
    "electronics.to_csv(\"electronic_products.csv\", index=False)\n",
    "\n",
    "#5\n",
    "check_df = pd.read_csv(\"electronic_products.csv\")\n",
    "print(check_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458629d",
   "metadata": {},
   "source": [
    "### 5. Binning Continuous Data (20 pts)\n",
    "\n",
    "Binning is a useful technique when you want to group continuous values into discrete intervals.  \n",
    "In this exercise, you’ll practice using `pd.cut` and `pd.qcut` with a dataset of exam scores.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "You are given a CSV file named **`exam_scores.csv`**.\n",
    "\n",
    "There are 100 students with scores ranging between 40 and 100.  \n",
    "\n",
    "---\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Load the dataset into a pandas DataFrame.\n",
    "2. Use `pd.cut` to bin the scores into 4 equal-width intervals:   (5 pts)\n",
    "   - `40–55` (Poor)  \n",
    "   - `55–70` (Average)  \n",
    "   - `70–85` (Good)  \n",
    "   - `85–100` (Excellent)  \n",
    "   Add a new column `category` with these labels.  \n",
    "\n",
    "3. Count how many students fall into each category.  (5 pts)\n",
    "\n",
    "4. Use `pd.qcut` to divide the scores into **quartiles (4 groups with equal number of students)**. Add a new column `quartile`. Display the first 10 rows in the new dataframe. (5 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f84a4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts per fixed-width bin (pd.cut):\n",
      "category\n",
      "Poor         22\n",
      "Average      27\n",
      "Good         23\n",
      "Excellent    28\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Counts per quantile bin (pd.qcut):\n",
      "quartile\n",
      "Q1    26\n",
      "Q2    24\n",
      "Q3    26\n",
      "Q4    24\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "      <th>quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>Good</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>Average</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>Average</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>Good</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id  score   category quartile\n",
       "0           1     45       Poor       Q1\n",
       "1           2     87  Excellent       Q4\n",
       "2           3     79       Good       Q3\n",
       "3           4     66    Average       Q2\n",
       "4           5     66    Average       Q2\n",
       "5           6     92  Excellent       Q4\n",
       "6           7     45       Poor       Q1\n",
       "7           8     82       Good       Q3\n",
       "8           9     52       Poor       Q1\n",
       "9          10     45       Poor       Q1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Load the dataset\n",
    "df = pd.read_csv(\"exam_scores.csv\")\n",
    "#display(df)\n",
    "\n",
    "#2) Fixed-width bins with pd.cut\n",
    "bins = [40, 55, 70, 85, 100]\n",
    "score_category = [\"Poor\", \"Average\", \"Good\", \"Excellent\"]\n",
    "\n",
    "df[\"category\"] = pd.cut(df[\"score\"], bins=bins, labels=score_category)\n",
    "#display(df)\n",
    "\n",
    "# 3) Count students per category\n",
    "cut_counts = df[\"category\"].value_counts().sort_index()\n",
    "print(\"Counts per fixed-width bin (pd.cut):\")\n",
    "print(cut_counts, \"\\n\")\n",
    "\n",
    "# 4) Quantile-based bins with pd.qcut (quartiles)\n",
    "df[\"quartile\"] = pd.qcut(df[\"score\"], q=4, labels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "qcut_counts = df[\"quartile\"].value_counts().sort_index()\n",
    "print(\"Counts per quantile bin (pd.qcut):\")\n",
    "print(qcut_counts, \"\\n\")\n",
    "\n",
    "# Display the first 10 rows in the new dataf rame.\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2161ad4",
   "metadata": {},
   "source": [
    "5. Compare the results of `pd.cut` (fixed-width bins) vs `pd.qcut` (quantile-based bins). (5 pts) \n",
    "   - Which method gives **evenly distributed counts** across groups?  \n",
    "   - Which method better preserves the interpretation of “score range”?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d5f03",
   "metadata": {},
   "source": [
    "Type your answer below:\n",
    "\n",
    "`pd.qcut`evenly distrbutes counts across groups, in our case I think there was no way to perfectly do so based on the values given as we have 26 and 24 in our bins.\n",
    "\n",
    "`pd.cut` is a better interpretation of score range as the ranges because we knew what bins we wanted to put our data into. Reading these bins is far more indicative of the distribution of scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebc2ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
